{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Task Learning(MTL) 가중치 비율 적용 모델\n",
    "클래스별 데이터 개수 비율에 따라 가중치 적용 비율을 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ho_e_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\tensor\\python_tensor.cpp:434.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "# GPU 설정\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 라벨링\n",
    "- CustomDataset 클래스에서 이미지 경로를 읽고, **파일명에 포함된 정보**를 바탕으로 라벨을 추출\n",
    "    - '_'를 기준으로 다섯 번째 값은 질병 정보\n",
    "    - '_'를 기준으로 여섯 번째 값은 작물 정보\n",
    "- 작물 번호와 질병 번호를 **라벨 매핑**을 통해 각각 0부터 시작하는 인덱스로 변환\n",
    "    - 원본 데이터셋의 일부 데이터만 사용하기 때문에 라벨값이 개수 범위를 벗어남 → 매핑 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, label_map, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.label_map = label_map  # 라벨 맵을 인자로 받음\n",
    "        self.image_paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        self.transform = transform if transform is not None else transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.image_paths[index]\n",
    "        filename = os.path.basename(path).split('_')\n",
    "\n",
    "        # 라벨 추출\n",
    "        disease_label = int(filename[4])  # 다섯 번째 항목이 질병 번호\n",
    "        crop_label = int(filename[5])     # 여섯 번째 항목이 작물 번호\n",
    "\n",
    "        # 라벨을 맵핑하여 처리\n",
    "        crop_label = torch.tensor(self.label_map['crop'][crop_label], dtype=torch.long)  \n",
    "        disease_label = torch.tensor(self.label_map['disease'][disease_label], dtype=torch.long)\n",
    "\n",
    "        # 이미지 로드 및 변환\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image, crop_label, disease_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 맵 정의\n",
    "label_map = {\n",
    "    'crop': {1: 0, 2: 1, 3: 2, 6: 3, 9: 4},  # 숫자와 인덱스를 매핑\n",
    "    'disease': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 11: 7, 12: 8, 16: 9, 17: 10, 18: 11}\n",
    "}\n",
    "\n",
    "# 데이터셋 준비\n",
    "train_dataset = CustomDataset(root_dir='./mtl_dataset_plus/Training', label_map=label_map)\n",
    "val_dataset = CustomDataset(root_dir='./mtl_dataset_plus/Validation', label_map=label_map)\n",
    "test_dataset = CustomDataset(root_dir='./mtl_dataset_plus/Test', label_map=label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔥 모델 구축 - Multi-Task_Learning(MTL) 모델\n",
    "\n",
    "1. **공유 백본(Backbone): ResNet-34**\n",
    "    - ResNet-34: 34개의 계층으로 구성된 잔차 네트워크(Residual Network)\n",
    "    - 사전 학습된 모델(`ResNet34_Weights.DEFAULT`)을 사용하여 초기화\n",
    "    - 마지막 Fully Connected(FC) Layer를 제외한 모든 계층을 공유\n",
    "    - 다중 태스크를 위해 마지막 Fully Connected(FC) Layer, 즉 분류기를 제거\n",
    "    - ResNet-34의 마지막 풀링 계층에서 추출된 특징은 512개의 차원(feature dimension)을 가지고 있음\n",
    "\n",
    "2. **태스크별 출력층(Task-Specific Heads)**\n",
    "    - 작물 분류와 질병 분류를 진행\n",
    "    - 각 분류기의 구조는 다음과 같음\n",
    "        1) Crop Head (작물 분류기)\n",
    "            - 입력 특징을 활용하여 5개 작물 클래스를 분류\n",
    "            - **출력 노드: 5개**\n",
    "            - 활성화 함수: Softmax 함수\n",
    "            - 손실 함수: CrossEntropyLoss\n",
    "\n",
    "        2) Disease Head (질병 분류기)\n",
    "            - 입력 특징을 활용하여 12개 질병 클래스를 분류\n",
    "            - **출력 노드: 12개**\n",
    "            - 활성화 함수: Softmax 함수\n",
    "            - 손실 함수: CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, backbone, num_crops, num_diseases):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.backbone = backbone  # ResNet-34 backbone\n",
    "        self.n_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()  # 마지막 fully connected layer(분류기) 제거\n",
    "        \n",
    "        # 태스크 특화 분류기\n",
    "        self.crop_head = nn.Linear(self.n_features, num_crops)          # 작물 클래스\n",
    "        self.disease_head = nn.Linear(self.n_features, num_diseases)    # 질병 클래스\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)  # 공유 backbone\n",
    "        crop_output = self.crop_head(features)  # 작물 분류 출력값\n",
    "        disease_output = self.disease_head(features)  # 질병 분류 출력값\n",
    "        return crop_output, disease_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성\n",
    "1. 공유 백본\n",
    "    - `resnet34(weights=ResNet34_Weights.DEFAULT)`\n",
    "    - 사전학습된 ResNet-34 모델 사용\n",
    "2. 모델 생성\n",
    "    - `MultiTaskModel(backbone, num_crops, num_diseases).to(device)`\n",
    "    - 분류할 클래스 수와 공유 백본을 인수로 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "num_crops = 5  # 작물 클래스 수\n",
    "num_diseases = 12  # 질병 클래스 수\n",
    "backbone = resnet34(weights=ResNet34_Weights.DEFAULT)  # 사전학습된 ResNet-34\n",
    "model = MultiTaskModel(backbone, num_crops, num_diseases).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 방식\n",
    "1. **손실 함수 정의**\n",
    "    - **클래스 불균형 문제 해결**\n",
    "        - 학습 데이터의 클래스별 샘플 개수가 불균형하므로, 이를 보정하기 위해 가중치를 적용한 손실 함수를 사용\n",
    "        - 계산된 가중치는 손실 함수에 적용되어 샘플이 적은 클래스에 더 큰 영향을 부여함\n",
    "        1) 학습 데이터셋을 순회하며, 각 클래스의 샘플 개수를 계산\n",
    "        2) 클래스별 샘플 개수의 역수를 기반으로 가중치를 계산\n",
    "    - 각 태스크의 손실 함수는 CrossEntropyLoss를 사용하되 각 태스크에 맞는 가중치 적용(`crop_class_weights`,`disease_class_weights`)\n",
    "    - 다중 태스크 학습의 총 손실은 두 태스크의 손실을 동일한 비율(0.5)로 가중합하여 계산\n",
    "    - **`Total Loss = 0.5 × Crop Loss + 0.5 × Disease Loss`**\n",
    "        - 작물 분류와 질병 분류의 손실을 *0.3:0.7* 비율로 실험을 해봤으나 **전반적으로 동일한 비율(0.5)로 가중합하였을 때 좋은 성능을 보임**\n",
    "\n",
    "\n",
    "2. **최적화 알고리즘**\n",
    "    - Adam Optimizer를 사용하여 네트워크의 가중치를 업데이트\n",
    "    - 학습률은 0.001로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 클래스별 샘플 개수 계산\n",
    "crop_counts = Counter()\n",
    "disease_counts = Counter()\n",
    "\n",
    "# 데이터셋 순회하며 라벨 수집\n",
    "for i in range(len(train_dataset)):\n",
    "    _, crop_label, disease_label = train_dataset[i]  # __getitem__ 호출\n",
    "    crop_counts[crop_label] += 1\n",
    "    disease_counts[disease_label] += 1\n",
    "\n",
    "# 클래스별 샘플 개수 출력\n",
    "print(\"Crop class counts:\", dict(crop_counts))\n",
    "print(\"Disease class counts:\", dict(disease_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스별 가중치 계산\n",
    "total_crop_samples = sum(crop_counts.values())\n",
    "total_disease_samples = sum(disease_counts.values())\n",
    "\n",
    "crop_class_weights = torch.tensor(\n",
    "    [total_crop_samples / crop_counts.get(c, 1) for c in range(num_crops)],\n",
    "    dtype=torch.float,\n",
    ").to(device)\n",
    "\n",
    "disease_class_weights = torch.tensor(\n",
    "    [total_disease_samples / disease_counts.get(d, 1) for d in range(num_diseases)],\n",
    "    dtype=torch.float,\n",
    ").to(device)\n",
    "\n",
    "print(\"Crop class weights:\", crop_class_weights)\n",
    "print(\"Disease class weights:\", disease_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 태스크별로 가중치 적용된 손실 함수 정의\n",
    "criterion_crop = nn.CrossEntropyLoss(weight=crop_class_weights)\n",
    "criterion_disease = nn.CrossEntropyLoss(weight=disease_class_weights)\n",
    "\n",
    "# 옵티마이저 정의\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard 설정\n",
    "writer = SummaryWriter('./runs_mtl/weight_mtl/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 및 검증 루프\n",
    "best_val_disease_acc = 0\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # ====== Training ======\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_crop = 0\n",
    "    correct_disease = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, crop_labels, disease_labels in train_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        crop_labels = crop_labels.to(device, non_blocking=True)\n",
    "        disease_labels = disease_labels.to(device, non_blocking=True)\n",
    "\n",
    "        # Optimizer 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward 및 손실 계산\n",
    "        crop_outputs, disease_outputs = model(images)\n",
    "        crop_loss = criterion_crop(crop_outputs, crop_labels)\n",
    "        disease_loss = criterion_disease(disease_outputs, disease_labels)\n",
    "        total_loss = 0.5 * crop_loss + 0.5 * disease_loss\n",
    "\n",
    "        # Backward 및 Optimizer 업데이트\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 손실 및 정확도 계산\n",
    "        running_loss += total_loss.item()\n",
    "        _, crop_predicted = torch.max(crop_outputs, 1)\n",
    "        _, disease_predicted = torch.max(disease_outputs, 1)\n",
    "        total += crop_labels.size(0)\n",
    "        correct_crop += (crop_predicted == crop_labels).sum().item()\n",
    "        correct_disease += (disease_predicted == disease_labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_crop_acc = 100 * correct_crop / total\n",
    "    train_disease_acc = 100 * correct_disease / total\n",
    "\n",
    "    # ====== Validation ======\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_crop = 0\n",
    "    correct_disease = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, crop_labels, disease_labels in val_loader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            crop_labels = crop_labels.to(device, non_blocking=True)\n",
    "            disease_labels = disease_labels.to(device, non_blocking=True)\n",
    "\n",
    "            # Forward 및 손실 계산\n",
    "            crop_outputs, disease_outputs = model(images)\n",
    "            crop_loss = criterion_crop(crop_outputs, crop_labels)\n",
    "            disease_loss = criterion_disease(disease_outputs, disease_labels)\n",
    "            val_loss += (0.5 * crop_loss + 0.5 * disease_loss).item()\n",
    "\n",
    "            # 정확도 계산\n",
    "            _, crop_predicted = torch.max(crop_outputs, 1)\n",
    "            _, disease_predicted = torch.max(disease_outputs, 1)\n",
    "            total += crop_labels.size(0)\n",
    "            correct_crop += (crop_predicted == crop_labels).sum().item()\n",
    "            correct_disease += (disease_predicted == disease_labels).sum().item()\n",
    "\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_crop_acc = 100 * correct_crop / total\n",
    "    val_disease_acc = 100 * correct_disease / total\n",
    "\n",
    "    # TensorBoard에 기록\n",
    "    writer.add_scalar('Train/Loss', train_loss, epoch)\n",
    "    writer.add_scalar('Train/Crop_Accuracy', train_crop_acc, epoch)\n",
    "    writer.add_scalar('Train/Disease_Accuracy', train_disease_acc, epoch)\n",
    "    writer.add_scalar('Validation/Loss', val_loss, epoch)\n",
    "    writer.add_scalar('Validation/Crop_Accuracy', val_crop_acc, epoch)\n",
    "    writer.add_scalar('Validation/Disease_Accuracy', val_disease_acc, epoch)\n",
    "\n",
    "    # 출력\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "            f'Train Loss: {train_loss:.4f}, Train Crop Acc: {train_crop_acc:.2f}%, Train Disease Acc: {train_disease_acc:.2f}%, '\n",
    "            f'Val Loss: {val_loss:.4f}, Val Crop Acc: {val_crop_acc:.2f}%, Val Disease Acc: {val_disease_acc:.2f}%')\n",
    "\n",
    "    # 모델 저장\n",
    "    if val_disease_acc > best_val_disease_acc:\n",
    "        best_val_disease_acc = val_disease_acc\n",
    "        best_model = model.state_dict()\n",
    "\n",
    "torch.save(best_model, 'best_weight_mtl_model.pth')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "model.load_state_dict(torch.load('best_weight_mtl_model.pth', weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "correct_crop = 0\n",
    "correct_disease = 0\n",
    "total = 0\n",
    "\n",
    "pred_crop_labels = []\n",
    "pred_disease_labels = []\n",
    "true_crop_labels = []\n",
    "true_disease_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, crop_labels, disease_labels in test_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        crop_labels = crop_labels.to(device, non_blocking=True)\n",
    "        disease_labels = disease_labels.to(device, non_blocking=True)\n",
    "\n",
    "        crop_outputs, disease_outputs = model(images)\n",
    "        _, crop_predicted = torch.max(crop_outputs, 1)\n",
    "        _, disease_predicted = torch.max(disease_outputs, 1)\n",
    "\n",
    "        total += crop_labels.size(0)\n",
    "        correct_crop += (crop_predicted == crop_labels).sum().item()\n",
    "        correct_disease += (disease_predicted == disease_labels).sum().item()\n",
    "\n",
    "        pred_crop_labels.extend(crop_predicted.cpu().numpy())\n",
    "        pred_disease_labels.extend(disease_predicted.cpu().numpy())\n",
    "        true_crop_labels.extend(crop_labels.cpu().numpy())\n",
    "        true_disease_labels.extend(disease_labels.cpu().numpy())\n",
    "\n",
    "test_crop_acc = 100 * correct_crop / total\n",
    "test_disease_acc = 100 * correct_disease / total\n",
    "\n",
    "print(f\"Test Crop Accuracy: {test_crop_acc:.2f}%\")\n",
    "print(f\"Test Disease Accuracy: {test_disease_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혼동 행렬 시각화 함수\n",
    "def plot_confusion_matrix(true_labels, pred_labels, classes, title, save_path=None):\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # 한글 폰트 설정\n",
    "    plt.rcParams['font.family'] = 'Malgun Gothic'  # 맑은고딕\n",
    "    plt.rcParams['axes.unicode_minus'] = False   # 마이너스 기호 깨짐 방지\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혼동 행렬 시각화\n",
    "plot_confusion_matrix(\n",
    "    true_crop_labels, \n",
    "    pred_crop_labels, \n",
    "    classes=['고추', '무', '배추', '오이', '파'], \n",
    "    title=\"Crop Classification Confusion Matrix\",\n",
    "    save_path='./basic_mtl/crop_confusion_matrix.png'\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    true_disease_labels, \n",
    "    pred_disease_labels, \n",
    "    classes=['정상', '고추탄저병', '고추흰가루병', '무검은무늬병', '무노균병', '배추검음썩음병', '배추노균병', '오이노균병', '오이흰가루병', '파검은무늬병', '파노균병', '파녹병'], \n",
    "    title=\"Disease Classification Confusion Matrix\",\n",
    "    save_path='./basic_mtl/disease_confusion_matrix.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6021 (pid 26732), started 0:00:12 ago. (Use '!kill 26732' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9fa8504ba4916e00\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9fa8504ba4916e00\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6021;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TensorBoard 실행 (주석 처리된 상태)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir './runs_mtl/' --port 6025"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
